#
#
# DESCRIPTION:
#
#       This project involves the implementation of Support Vector Machine (SVM) on simulated data
# 
# DATASET:
#
#       The dataset  was generated by defining the polynomial function of degree 2 ( Pol(x) = ??i ??j Aij xi xj + ?? i Bi xi + c/20 ) 
#
#       in the 4 variables x1 x2 x3 x4 as follows
#
#       We seek to generate 5000 cases x1 ... x5000 in R4. Each case x = [ x1 x2 x3 x4 ] has 4 numerical features
#
#       and Aij, Bi and c are random numbers set as coefficients of the equation.
#
#
#   STEPS:
#
#        1) Define the polynomila function of degree 2 with 16 random numbers for Aij, 4 random numbers for Bi and 1 for C

#       2)  Implement SVM classification by linear kernel and later optimize the cost parameter 
#       
#       3)  Implement SVM classification by radial kernel and later optimize the cost"and "gamma" parameters 
#
#       4)  Implement SVM classification using a polynomial kernel
#




#       PART 1
#
#
#
#            Data Set generation by Simulations
#
#

set.seed(178900999)  # Define the seed

Aij= runif(16, min=-2, max=2) #generate 16 random numbers for A

Aij=matrix(Aij, byr=4, ncol=4)

Bi=runif(4, min=-2, max=2)  #generate 4 random numbers for B

Bi = matrix(Bi, byr=1, ncol=4)

C=runif(1, min=-2, max=2)  #generate 1 random number for C

C=C/20



#         Defining the polynomial function for estimating the separator
#
#
#         Pol(x) = ??i ??j Aij xi xj + ?? i Bi xi + c/20  
#



b = function(X1, X2, X3, X4){
  
    seperator = list()
    
    for (i in 1:10000)
      
        {
    
    x= c(X1[i],X2[i],X3[i],X4[i]) 
    
    x = matrix(x)
    
    x1 = t(x)
    
    suma = sum (Aij %*% x %*% x1 )
    
    sumb = sum (Bi %*% x)
    
    total = sum(suma, sumb, C)
    
    seperator[i] = total
    
    i=i+1
    
    }
    
  seperator1 = do.call(rbind, seperator)
  
}


#
#
#                   Data generation

 

set.seed(178900999)  #use the same random numbers

data1 = runif(40000, min=-2, max=2) #generate 16 random numbers for A

data=data.frame(matrix(data1, byr=10000, ncol=4)) 

seperator1= b(data$X1,data$X2,data$X3,data$X4) #estimating the separator 

data["X5"]=sign(seperator1) #including the sign of the separator in the dataset

CL1=subset(data, data$X5>0) # defining the data set for class 1 

CL_1=subset(data, data$X5<0) # defining the data set for class -1

CL1_2500=CL1[1:2500,] #keeping only 2500 for class 1

CL_1_2500=CL_1[1:2500,] #keeping only 2500 for class -1


CL1_newstd= apply(CL1_2500, 2, scale) #rescaling class 1

CL1_newstd[is.nan(CL1_newstd)] = 1


CL_1_newstd= apply(CL_1_2500, 2, scale) #rescaling class -1

CL_1_newstd[is.nan(CL_1_newstd)] = -1



#
#        Preparing the training and test set for class 1
#
#
class1 = sort(sample(nrow(CL1_newstd), nrow(CL1_newstd)*0.8)) #80% of the training set


#       creating training data set by selecting the output row values

trainclass1=CL1_newstd[class1,]

#       creating test data set by not selecting the output row values

testclass1=CL1_newstd[-class1,]

#
#        Preparing the training and test set for class 2
#

class2 = sort(sample(nrow(CL_1_newstd), nrow(CL_1_newstd)*0.8)) # 80% of the training set

#      creating training data set by selecting the output row values

trainclass2<-CL_1_newstd[class2,]


#           creating test data set by not selecting the output row values

testclass2<-CL_1_newstd[-class2,]


#               Training Set

total_train = data.frame (rbind(trainclass1, trainclass2)) #Merging class 1 and class -1 

head(total_train) #display the the top rows of the training set

summary(total_train) #display the summary of training set

nrow(total_train) #Size of the training set


#               Test Set

total_test = data.frame(rbind (testclass1,testclass2 )) #Merging class 1 and -1

head(total_test)  #display the the top rows of the test set

summary(total_test)#display the summary of test set

nrow(total_test) #size of the test set


#
#
#      PART 2:
#
#                 SVM classification by Linear Kernel
#
#
#

options(digits=4) #4 decimal numbers

library(e1071)

y=(total_train[,5]) #true prediction for train set

x=(total_train[,1:4]) #training set input cases

y_test = total_test [,5] #true prediction for test case

x_test = total_test [,1:4]#test case input cases





#
#            Launch the svm on the train data set for cost=5
#
#              Fix arbitrarily the "cost" parameter i.e. cost = 5


svmfit = svm(y~., x,type="C-classification",kernel="linear",cost=5,scale =FALSE) 

summary(svmfit)




#
#  2a.  RESULTS OF SVM 
#



nsv = svmfit$nSV

#        number of support vectors

nsv

#       Total number of support vectors

S=svmfit$tot.nSV


#       Total number of support vectors
S


#       Ratio of support vectors

s=svmfit$tot.nSV/nrow(x) #nrow(x) =4000



#       Ratio of number of support vectors over cases
s




#
#   2b. Percentages of correct classification for train
#

y_pred = predict(svmfit, x) #prediction on the training set

y_test_pred = predict(svmfit, x_test) #prediction on the test set



library(caret) 

cft=confusionMatrix(y_pred, as.factor(y))

PredTrain=cft$overall[1]

PredTrain1= data.frame(t(matrix(c(cft$overall[1:4]))))

PredTrain1$X2=NULL; colnames(PredTrain1) = c("Accuracy","AccuracyLower","AccuracyUpper")

PredTrain1 #Percentage of correct classification on the training set with 95% Confidence Interval computed by r 


error= sqrt(PredTrain*(1-PredTrain)/nrow(data.frame(y_pred)))

AccuracyLower=(-1.6*error)+PredTrain

AccuracyUpper= (1.6*error)+PredTrain

results= data.frame(t(matrix(c(PredTrain, AccuracyLower, AccuracyUpper))))

colnames(results) = c("Accuracy","CI(AccuracyLower)","CI(AccuracyUpper)")

results#Percentage of correct classification on the training set with 95% Confidence Interval manual computation




#
# 2c.        Percentages of correct classification for Test set
#

cftest=confusionMatrix(y_test_pred,as.factor(y_test))

PredTest = cftest$overall[1]

PredTest1= data.frame(t(matrix(c(cftest$overall[1:4]))))

PredTest1$X2=NULL; colnames(PredTest1) = c("Accuracy","AccuracyLower","AccuracyUpper")

PredTest1 #Percentage of correct classification on the test set with 95% Confidence Interval computed by r




error1= sqrt(PredTest*(1-PredTest)/nrow(data.frame(y_test_pred)))

AccuracyLowert=(-1.6*error1)+PredTest

AccuracyUppert= (1.6*error1)+PredTest

resultst= data.frame(t(matrix(c(PredTest, AccuracyLowert, AccuracyUppert))))

colnames(resultst) = c("Accuracy","CI(AccuracyLower)","CI(AccuracyUpper)")

resultst #Percentage of correct classification on the test set with 95% Confidence Interval manual computation





#
#  2d.    Confusion Matrix for Training Set Using Numbers, Frequency and Error
#

cmtr=cft$table

cmtr # confusion matrix in terms of numbers of correct classification 

p_cmtr=(rbind(cmtr[1,]/(sum(cmtr[1,])), cmtr[2,]/(sum(cmtr[2,]))))

p_cmtr#confusion matrix in terms of percentage 

error111= sqrt((p_cmtr[1,])*(1-p_cmtr[1,])/sum(p_cmtr[1,]))

error121= sqrt((p_cmtr[2,])*(1-p_cmtr[2,])/sum(p_cmtr[2,]))

error31 = rbind(error111, error121) 
error31  #error on the confusion matrix percentage for train set




#
#  2e.     Confusion Matrix for Test set using Numbers, Frequency and Error
#

cftestte = cftest$table 

cftestte #Confusion Matrix in terms of number of correct classification 

p_cmtrte=(rbind(cftestte[1,]/(sum(cftestte[1,])), cftestte[2,]/(sum(cftestte[2,]))))

p_cmtrte #cCnfusion Matrix in terms of percentage 

error11te= sqrt((p_cmtrte[1,])*(1-p_cmtrte[1,])/sum(p_cmtrte[1,]))

error12te= sqrt((p_cmtrte[2,])*(1-p_cmtrte[2,])/sum(p_cmtrte[2,]))

error3te = rbind(error11te, error12te) 

error3te  #Error on the Confusion Matrix Percentage for test set




#
#   Error of Estimation for Training Set
#

matrix(error) #Error of estimation for PredTrain

PredTrain1 #Percentage of correct classification on the training set with 95% Confidence Interval computed by r

results #Percentage of correct classification on the training set with 95% Confidence Interval manual computation

error31   #error on the confusion matrix for the train set


#
#    Error of Estimation for Test Set
#

matrix(error1) #Error of estimation for PredTest

PredTest1 #Percentage of correct classification on the test set with 95% Confidence Interval computed by r

resultst #Percentage of correct classification on the test set with 95% Confidence Interval manual computation

error3te  #Error on the confusion matrix percentage for test set




#
#
#      PART 3: 
#     
#         Optimize the parameter "cost" for Linear Kernel
#
#

#
#          Launch the svm on the train data for manual tuning (before using the in-built in r)
#

#             6 cost parameters chosen for tuning:   cost = [0.01, 0.1, 1, 10, 20, 50]
#

svmfit0.01 =svm(y~., x, type= "C-classification", kernel = "linear", cost = 0.01, scale =FALSE) #cost = 0.01

svmfit0.1 =svm(y~., x, type= "C-classification", kernel = "linear", cost = 0.1, scale =FALSE)    #cost = 0.1

svmfit1 =svm(y~., x, type= "C-classification", kernel = "linear", cost = 1, scale =FALSE)        #cost = 1

svmfit10 =svm(y~., x, type= "C-classification", kernel = "linear", cost = 10, scale =FALSE)      #cost = 10

svmfit20 =svm(y~., x, type= "C-classification", kernel = "linear", cost = 20, scale =FALSE)      #cost = 20

svmfit50 =svm(y~., x, type= "C-classification", kernel = "linear", cost = 50, scale =FALSE)      #cost = 50


#
#             Launch the svm results for manual tuning
#

#
#             cost=0.01
#

rnsv0.01=svmfit0.01$tot.nSV/nrow(x) #ratio of support vectors 

y_pred0.01 = predict(svmfit0.01, x) # prediction of result, training set

cft0.01=confusionMatrix(as.factor(y), y_pred0.01) #confusion matrix for training set

PredTrain10.01 = cft0.01$overall[1] #performance with 95% confidence interval training set

error0.01train= sqrt(PredTrain10.01*(1-PredTrain10.01)/nrow(data.frame(y_pred0.01))) #error 

y_test_pred0.01 = predict(svmfit0.01, x_test) # prediction of result, test set

cftest0.01=confusionMatrix(as.factor(y_test), y_test_pred0.01) #confusion matrix for test set

PredTest10.01 = cftest0.01$overall[1] #Performance with 95% confidence interval of test set

error0.01test= sqrt(PredTest10.01*(1-PredTest10.01)/nrow(data.frame(y_test_pred0.01))) #error




#
#                  cost=0.1
#

rnsv0.1=svmfit0.1$tot.nSV/nrow(x) #ratio of support vectors

y_pred0.1 = predict(svmfit0.1, x) # prediction of result, training set

cft0.1=confusionMatrix(as.factor(y), y_pred0.1) #confusion matrix for training set

PredTrain10.1 = cft0.1$overall[1] #performance with 95% confidence interval training set

error0.1train= sqrt(PredTrain10.1*(1-PredTrain10.1)/nrow(data.frame(y_pred0.1)))#error

y_test_pred0.1 = predict(svmfit0.1, x_test) # prediction of result, test set

cftest0.1=confusionMatrix(as.factor(y_test), y_test_pred0.1) #confusion matrix for test set

PredTest10.1 = cftest0.1$overall[1] #Performance with 95% confidence interval of test set

error0.1test= sqrt(PredTest10.1*(1-PredTest10.1)/nrow(data.frame(y_test_pred0.1))) #error



#
#                    cost=1
#

rnsv1=svmfit1$tot.nSV/nrow(x) #ratio of support vectors

y_pred1 = predict(svmfit1, x) # prediction of result, training set

cft1=confusionMatrix(as.factor(y), y_pred1) #confusion matrix for training set

PredTrain11 = cft1$overall[1] #performance with 95% confidence interval training set

error221train= sqrt(PredTrain11*(1-PredTrain11)/nrow(data.frame(y_pred1)))  #error 

y_test_pred1 = predict(svmfit1, x_test) # prediction for result test set

cftest1=confusionMatrix(as.factor(y_test), y_test_pred1) #confusion matrix for test set

PredTest11 = cftest1$overall[1] #Performance with 95% confidence interval of test set

error221test= sqrt(PredTest11*(1-PredTest11)/nrow(data.frame(y_test_pred1))) #error 




#
#                         cost=10
#

rnsv10=svmfit10$tot.nSV/nrow(x) #ratio of support vectors

y_pred10 = predict(svmfit10, x) # prediction of result training set

cft10=confusionMatrix(as.factor(y), y_pred10) #confusion matrix for training set

PredTrain110 = cft10$overall[1] #performance with 95% confidence interval training set

error221train10= sqrt(PredTrain110*(1-PredTrain110)/nrow(data.frame(y_pred10)))  #error 

y_test_pred10 = predict(svmfit10, x_test) # prediction of result, test set

cftest10=confusionMatrix(as.factor(y_test), y_test_pred10) #confusion matrix for test set

PredTest110 = cftest10$overall[1] #performance with 95% confidence interval test set

error221test10= sqrt(PredTest110*(1-PredTest110)/nrow(data.frame(y_test_pred10))) #error 


#
#                         cost=20
#

rnsv20=svmfit20$tot.nSV/nrow(x) #ratio of support vectors

y_pred20 = predict(svmfit20, x) # prediction for result training set

cft20=confusionMatrix(as.factor(y), y_pred20) #confusion matrix for training set

PredTrain120 = cft20$overall[1] #performance with 95% confidence interval training set

error221train20= sqrt(PredTrain120*(1-PredTrain120)/nrow(data.frame(y_pred20))) #error 

y_test_pred20 = predict(svmfit20, x_test) # prediction of result, test set

cftest20=confusionMatrix(as.factor(y_test), y_test_pred20) #confusion matrix for test set

PredTest120 = cftest20$overall[1]  #performance with 95% confidence interval test set

error221test20= sqrt(PredTest120*(1-PredTest120)/nrow(data.frame(y_test_pred20))) #error 


#
#                         cost=50
#

rnsv50=svmfit50$tot.nSV/nrow(x) #ratio of support vectors

y_pred50 = predict(svmfit50, x) # prediction for result training set

cft50=confusionMatrix(as.factor(y), y_pred50) #confusion matrix for training set

PredTrain150 = cft50$overall[1] #performance with confidence interval training set

error221train50= sqrt(PredTrain150*(1-PredTrain150)/nrow(data.frame(y_pred50)))  #error 

y_test_pred50 = predict(svmfit50, x_test) # prediction for result test set

cftest50=confusionMatrix(as.factor(y_test), y_test_pred50) #confusion matrix for test set

PredTest150 = cftest50$overall[1] #performance with 95% confidence interval test set

error221test50= sqrt(PredTest150*(1-PredTest150)/nrow(data.frame(y_test_pred50))) #error 

cost1=c(0.01, 0.1 , 1, 5, 10, 20, 50) #including previous cost=5 results

ratio_SV= c(rnsv0.01, rnsv0.1, rnsv1, s, rnsv10, rnsv20, rnsv50) #all ratio of support vectors

Performance_trainset = c(PredTrain10.01, PredTrain10.1, PredTrain11, PredTrain,
                         
                         PredTrain110, PredTrain120, PredTrain150) #PredTrain

Error_PredTrain = c(error0.01train, error0.1train, error221train, error, 
                    
                    error221train10, error221train20, error221train50 )

Performance_testset = c(PredTest10.01, PredTest10.1, PredTest11, PredTest,
                        
                        PredTest110, PredTest120, PredTest150) #All Predtest

Error_PredTest = c(error0.01test, error0.1test, error221test, error1, error221test10,
                   
                   error221test20, error221test50 )

testresults = data.frame(cost1, ratio_SV, Performance_trainset, Error_PredTrain, 
                         
                         Performance_testset, Error_PredTest)

testresults



#
#
#                        Launch the svm on the train data for tuning using inbuilt in r
#


set.seed (1)   #set the seed

tune.out=tune(svm, train.x=x, train.y=as.factor(y), type= "C-classification", kernel = "linear",
              ranges =list(cost=c(0.01, 0.1 , 1,5, 10, 20, 50) ))

options(digits=5)

tune.out$performances #performance results for the 6 cost and previous cost=5

tune.out$best.parameters #best cost model




#
#                       Plot result
#

plot(cost1,tune.out$performances$error,xlim=range(c(cost1)),
     
     ylim=range(c(tune.out$performances$error,tune.out$performances$dispersion)),
     
     col="red", pch=16, cex=0.5, xlab = "Cost", ylab=" Error and Dispersion", 
     
     main='2 Dimensional Scatter Plots', col.axis='red')

lines(lowess(cost1,tune.out$performances$error),col="red", pch=16)

points(cost1,tune.out$performances$dispersion,col="blue", pch=16, cex=0.5)

lines(lowess(cost1,tune.out$performances$dispersion),col="blue", pch=16)

legend(x=40, y=0.51, legend=c('Error', 'Dispersion'), col=c('red', 'blue'), pch=c(16, 16))





#               Evaluate the performance characteristics of the "best" linear svm from above
#
#
#                    Performance characteristics for best model i.e cost = 1
#

bestmodel= tune.out$best.model

ybestmodelpred = predict(bestmodel,x)

ybestmodelpredtest = predict(bestmodel,x_test)



#
#                Percentage of correct classification for best model (Train Set)
#

options(digits=5)

cftbest=confusionMatrix(ybestmodelpred, as.factor(y))

bestmodel12=cftbest$overall[1]

bestmodel1= data.frame(t(matrix(c(cftbest$overall[1:4]))))

bestmodel1$X2=NULL; colnames(bestmodel1) = c("Accuracy","AccuracyLower","AccuracyUpper")

bestmodel1 #Percentage of correct classification on the best mdoel with 95% Confidence Interval computed by r


errorbest= sqrt(bestmodel12*(1-bestmodel12)/nrow(data.frame(ybestmodelpred)))

AccuracyLowerbest=(-1.6*errorbest)+bestmodel12

AccuracyUpperbest= (1.6*errorbest)+bestmodel12

resultsbest= data.frame(t(matrix(c(bestmodel12,AccuracyLowerbest,AccuracyUpperbest))))

colnames(resultsbest) = c("Accuracy","CI(AccuracyLower)","CI(AccuracyUpper)")

resultsbest #Percentage of correct classification on the best model with 95% Confidence Interval manual computation




#
#              Percentage of correct classification for best model (Test Set)
#

options(digits=5)

cftestbest=confusionMatrix(ybestmodelpredtest, as.factor(y_test))

bestmodel12test=cftestbest$overall[1]

bestmodel1test= data.frame(t(matrix(c(cftestbest$overall[1:4]))))

bestmodel1test$X2=NULL; colnames(bestmodel1test) = c("Accuracy",
                                                     "AccuracyLower","AccuracyUpper")

bestmodel1test #Percentage of correct classification with 95% Confidence Interval computed by r on the test set

errortestbest= sqrt(bestmodel12test*(1-bestmodel12test)
                    
                    /nrow(data.frame(ybestmodelpredtest)))

AccuracyLowertestbest=(-1.6*errortestbest)+bestmodel12test

AccuracyUppertestbest= (1.6*errortestbest)+bestmodel12test

resultstestbest= data.frame(t(matrix(
  
  c(bestmodel12test,AccuracyLowertestbest,AccuracyUppertestbest))))

colnames(resultstestbest) = c("Accuracy","CI(AccuracyLower)","CI(AccuracyUpper)")

resultstestbest #Percentage of correct classification with 95% Confidence Interval manual computation on the test set




#
#                 Confusion Matrix for Train set using Numbers, Frequency and Error
#



options(digits=5)

cmtrbest=cftbest$table

cmtrbest # Confusion Matrix in terms of numbers of correct classification

p_cmtrbest=(rbind(cmtrbest[1,]/(sum(cmtrbest[1,])),cmtrbest[2,]/(sum(cmtrbest[2,]))))

p_cmtrbest#Confusion Matrix in terms of percentage/frequency 

error11best= sqrt((p_cmtrbest[1,])*(1-p_cmtrbest[1,])/sum(p_cmtrbest[1,]))

error12best= sqrt((p_cmtrbest[2,])*(1-p_cmtrbest[2,])/sum(p_cmtrbest[2,]))

error3best = rbind(error11best, error12best) 

error3best  #Error on the confusion matrix percentage for best model



#
#                    Confusion Matrix for Test set using Numbers, Frequency and Error with Linear Kernel
#

options(digits=4)

cmtrtestbest=cftestbest$table

cmtrtestbest                      # Confusion Matrix in terms of number of correct classification

p_cmtrtestbest=(rbind(cmtrtestbest[1,]/(sum(cmtrtestbest[1,])),
                      
                      cmtrtestbest[2,]/(sum(cmtrtestbest[2,]))))

p_cmtrtestbest#Confusion matrix in terms of percentage 

error11testbest= sqrt((p_cmtrtestbest[1,])*(1-p_cmtrtestbest[1,])
                      
                      /sum(p_cmtrtestbest[1,]))

error12testbest= sqrt((p_cmtrtestbest[2,])*(1-p_cmtrtestbest[2,])
                      
                      /sum(p_cmtrtestbest[2,]))

error3testbest = rbind(error11testbest, error12testbest) 

error3testbest  #error on the confusion matrix percentage for best model


#
#                      Error of Estimation for Train Set for best model with Linear Kernel
#

matrix(errorbest) #error of estimation for best model

bestmodel1  #Percentage of correct classification for the best model with 95% Confidence Interval computed by r

resultsbest #Percentage of correct classification for the best model with 95% Confidence Interval manual computation

error3best  #error on the confusion matrix for the best model




#
#                     Error of Estimation for Test Set for best model with Linear Kernel
#


matrix(errortestbest) #error of estimation for best model

bestmodel1test  #Percentage of correct classification for the best model with 95% Confidence Interval computed by r

resultstestbest #Percentage of correct classification for the best model with 95% Confidence Interval manual computation

error3testbest  #error on the confusion matrix for the best model


#
#                       Interpretation of result
#


d = c(svmfit0.01$tot.nSV/nrow(x),svmfit0.1$tot.nSV/nrow(x),svmfit1$tot.nSV/nrow(x),svmfit$tot.nSV/nrow(x),
      
      svmfit10$tot.nSV/nrow(x),svmfit20$tot.nSV/nrow(x),svmfit50$tot.nSV/nrow(x))

#
#                          Number of support vectors
# 

plot(cost1,d,xlab = "Cost", ylab="Number of support vectors", main='2 Dimensional Scatter Plots', col.axis='red', pch=16)

lines(lowess(cost1,d),col="red", pch=16)

#
#                            Performances versus cost
#
plot(cost1,Performance_trainset,xlim=range(c(cost1)),ylim=range(c(Performance_testset,Performance_trainset)),
     
     col="red", pch=16, cex=0.5, xlab = "Cost", ylab="Performances", 
     
     main='2 Dimensional Scatter Plots', col.axis='red')

lines(lowess(cost1,Performance_trainset),col="red", pch=16)

points(cost1,Performance_testset,col="blue", pch=16, cex=0.5)

lines(lowess(cost1,Performance_testset),col="blue", pch=16)

legend(x=20, y=0.51, legend=c('Training Set', 'Test Set'), col=c('red', 'blue'), pch=c(16, 16))





#
#         PART 4: 
#
#                   SVM classification by radial kernel
#
#
#            Fix the "cost" parameter in the svm () function to the best cost value identified
#
#
#
#            Launch the svm on the train data set 


svmfitradial =svm(y~.,x, type="C-classification",kernel="radial",cost = 1,gamma=1,scale =FALSE)
                  


#             Number of support vectors


nsvradial=svmfitradial$nSV

nsvradial        #number of support vectors


  
Sradial=svmfitradial$tot.nSV

Sradial         #total number of support vectors



sradial=svmfitradial$tot.nSV/nrow(x)     

sradial      # ratio of number of support vectors over cases



y_predradial = predict(svmfitradial, x) #prediction on the training set

y_test_predradial = predict(svmfitradial, x_test) #prediction on the test set


#
#    Percentages of correct classification for the Train set using the radial kernel
#


cftradial=confusionMatrix(y_predradial, as.factor(y)) 

Predradialtrain=cftradial$overall[1]

Predradialtrain1= data.frame(t(matrix(c(cftradial$overall[1:4]))))

Predradialtrain1$X2=NULL; colnames(Predradialtrain1) = c("Accuracy","AccuracyLower","AccuracyUpper")

Predradialtrain1 #Percentage of correct classification on the train set with 95% Confidence Interval computed by r


errorradial= sqrt(Predradialtrain*(1-Predradialtrain)/nrow(data.frame(y_predradial)))
                  
AccuracyLowerradial=(-1.6*error)+Predradialtrain

AccuracyUpperradial= (1.6*error)+Predradialtrain

resultsradial= data.frame(t(matrix(c(Predradialtrain,AccuracyLowerradial,AccuracyUpperradial))))
                                     
colnames(resultsradial) = c("Accuracy","CI(AccuracyLower)","CI(AccuracyUpper)")

resultsradial #Percentage of correct classification on the train set with 95%Confidence Interval manual computation
 


#
#              Percentages of correct classification for the Test set using the radial kernel
#



cftestradial=confusionMatrix(y_test_predradial,as.factor(y_test))

PredTestradial = cftestradial$overall[1]

PredTest1radial= data.frame(t(matrix(c(cftestradial$overall[1:4]))))

PredTest1radial$X2=NULL; colnames(PredTest1radial) = c("Accuracy","AccuracyLower","AccuracyUpper")
  
PredTest1radial #Percentage of correct classification on the test set with 95%  Confidence Interval computed by r



error1radial= sqrt(PredTestradial*(1-PredTestradial)/nrow(data.frame(y_test_predradial)))

AccuracyLowertradial=(-1.6*error1radial)+PredTestradial

AccuracyUppertradial= (1.6*error1radial)+PredTestradial

resultstradial1= data.frame(t(matrix(c(PredTestradial,AccuracyLowertradial,AccuracyUppertradial))))
                                       
colnames(resultstradial1) = c("Accuracy"," CI(AccuracyLower)","CI(AccuracyUpper)")

resultstradial1    #Percentage of correct classification on the test set with 95%  Confidence Interval manual computation



#
#               Confusion Matrix for SVM classification for Training set using the radial kernel
#


cmttradial=cftradial$table

cmttradial # Confusion Matrix in terms of number of correct classification

p_cmttradial=(rbind(cmttradial[1,]/(sum(cmttradial[1,])),  cmttradial[2,]/(sum(cmttradial[2,]))))
                   
p_cmttradial      #confusion matrix in terms of percentage 

error11tradial= sqrt((p_cmttradial[1,])*(1-p_cmttradial[1,])/sum(p_cmttradial[1,]))
                     
error12tradial= sqrt((p_cmttradial[2,])*(1-p_cmttradial[2,])/sum(p_cmttradial[2,]))
                     
error3tradial = rbind(error11tradial, error12tradial) 

error3tradial  #error on the confusion matrix percentage for train set



#
#               Confusion Matrix for SVM classification for Test set using the radial kernel
#

cteradial = cftestradial$table

cteradial                     #confusion matrix in terms of numbers

p_cteradial=(rbind(cteradial[1,]/(sum(cteradial[1,])), cteradial[2,]/(sum(cteradial[2,]))))
                  
p_cteradial                 #confusion matrix in terms of percentage 

error11teradial= sqrt((p_cteradial[1,])*(1-p_cteradial[1,])/sum(p_cteradial[1,]))
                      
error12teradial= sqrt((p_cteradial[2,])*(1-p_cteradial[2,])/sum(p_cteradial[2,]))
                      
error3teradial = rbind(error11teradial, error12teradial) 

error3teradial  #error on the confusion matrix percentage for test set




#
#                Errors of estimation for training set using the radial kernel
#


matrix(errorradial) #error of estimation for PredTrain

Predradialtrain1 #Percentage of correct classification on the training set with  Confidence Interval computed by r

resultsradial #Percentage of correct classification on the training set with  Confidence Interval manual computation

error3tradial #error on the confusion matrix for the train set


#
#                 Errors of estimation for test set using the radial kernel
#

matrix(error1radial) #error of estimation for PredTest

PredTest1radial #Percentage of correct classification on the test set with 95%  Confidence Interval computed by r

resultstradial1 #Percentage of correct classification on the test set with 95%  Confidence Interval manual computation

error3teradial #error on the confusion matrix percentage for test set







#    PART 5:
#
#          optimize the parameter "cost"and "gamma" for radial kernel
#
#
#           Select a list of 5 values for the "cost " parameter and a list of 5 values for the parameter "gamma"
#
#
#
#                                 Launch the tuning svm function

tune_rad_optimize = tune.svm(as.factor(X5)~.,data=total_train,type="C-classification",kernel="radial",
                             
                             gamma= c(0.5, 1, 2,3,4), cost = c(0.01, 0.1 , 1,5, 10))

tune_rad_optimize$performances #performance results for 5 different costs and 5 different gamma 

tune_rad_optimize$best.parameters #best performance


#                    Plot result

plot(tune_rad_optimize$performances$cost, tune_rad_optimize$performances$error,
    
     xlim=range(c(tune_rad_optimize$performances$cost)),
     
     ylim=range(c(tune_rad_optimize$performances$error,
                  
                  tune_rad_optimize$performances$dispersion)),
     
     col="red", pch=16, cex=0.5, xlab = "Cost", ylab=" Error and Dispersion",
     
     main='2 Dimensional Scatter Plots', col.axis='red')

lines(lowess(tune_rad_optimize$performances$cost,
             tune_rad_optimize$performances$error),col="red", pch=16)
points(tune_rad_optimize$performances$cost,
       tune_rad_optimize$performances$dispersion,col="blue", pch=16, cex=0.5)
lines(lowess(tune_rad_optimize$performances$cost,
             tune_rad_optimize$performances$dispersion),col="blue", pch=16)
legend(x=5,y=0.4,legend=c('Error','Dispersion'),col=c('red','blue'),pch=c(16, 16))





#                         Evaluate the performance characteristics of the "best" radial svm
#
#       Prediction on the training and test sets using the best model i.e. cost=5  and gamma=0.5 as indicated above
#




bestmodelgamma=tune_rad_optimize$best.model

ybestgammapred = predict(bestmodelgamma,x) #Train set

ybestgammapredtest = predict(bestmodelgamma,x_test) #Test set



#
#                    Percentage of correct classification for the best radial model (Training Set)
#


cftbestgamma=confusionMatrix(ybestgammapred, as.factor(y))

bestmodel12gamma=cftbestgamma$overall[1]

bestmodel1gamma= data.frame(t(matrix(c(cftbestgamma$overall[1:4]))))

bestmodel1gamma$X2=NULL; colnames(bestmodel1gamma) = c("Accuracy","AccuracyLower","AccuracyUpper")
                                                       
bestmodel1gamma          #Percentage of correct classification on the best mdoel with  Confidence Interval computed by r

errorbestgamma1= sqrt(bestmodel12gamma*(1-bestmodel12gamma)/nrow(data.frame(ybestgammapred)))
                      
AccuracyLowerbestgamma1=(-1.6*errorbestgamma1)+bestmodel12gamma

AccuracyUpperbestgamma1= (1.6*errorbestgamma1)+bestmodel12gamma

resultsbestgamma1=data.frame(t(matrix(c(bestmodel12gamma,AccuracyLowerbestgamma1,AccuracyUpperbestgamma1))))
                                        
colnames(resultsbestgamma1) =c("Accuracy","CI(AccuracyLower)","CI(AccuracyUpper)")
  
resultsbestgamma1 #  Percentage of correct classification on the best model with 95%  Confidence Interval manual computation




#
#                      Percentage of correct classification for the best radial model (Test Set)
#

options(digits=4)

cftbestgammatest=confusionMatrix(ybestgammapredtest, as.factor(y_test))

bestmodel12gammatest=cftbestgammatest$overall[1]

bestmodel1gammatest= data.frame(t(matrix(c(cftbestgammatest$overall[1:4]))))

bestmodel1gammatest$X2=NULL; colnames(bestmodel1gammatest) = c("Accuracy","AccuracyLower","AccuracyUpper")
                                                               

bestmodel1gammatest #Percentage of correct classification on the best mdoel with 95%  Confidence Interval computed by r

errorbestgammatest= sqrt(bestmodel12gammatest*(1-bestmodel12gammatest)/nrow(data.frame(ybestgammapredtest)))
                           
AccuracyLowerbestgammatest=(-1.6*errorbestgammatest)+bestmodel12gammatest

AccuracyUpperbestgammatest= (1.6*errorbestgammatest)+bestmodel12gammatest

resultsbestgammatest=data.frame(t(matrix(c(bestmodel12gammatest,AccuracyLowerbestgammatest,
                                           
                                           AccuracyUpperbestgammatest))))

colnames(resultsbestgammatest) = c("Accuracy","CI(AccuracyLower)","CI(AccuracyUpper)")
                                   
resultsbestgammatest #Percentage of correct classification on the best model with 95%  Confidence Interval manual computation
  



#
#                      Confusion matrix for best radial model (Training Set)
#


options(digits=4)

cmtbestgamma=cftbestgamma$table

cmtbestgamma                   # confusion matrix in terms of numbers

p_cmtbestgamma=(rbind(cmtbestgamma[1,]/(sum(cmtbestgamma[1,])), cmtbestgamma[2,]/(sum(cmtbestgamma[2,]))))
                      
p_cmtbestgamma#confusion matrix in terms of percentage 

error11bestgamma= sqrt((p_cmtbestgamma[1,])*(1-p_cmtbestgamma[1,]) /sum(p_cmtbestgamma[1,]))
                      
error12bestgamma= sqrt((p_cmtbestgamma[2,])*(1-p_cmtbestgamma[2,])/sum(p_cmtbestgamma[2,]))
                       
error3bestgamma = rbind(error11bestgamma, error12bestgamma) 

error3bestgamma             #error on the confusion matrix percentage for best model




#
#                      Confusion matrix for best radial model (Test Set)
#



options(digits=4)

cmtbestgammatest=cftbestgammatest$table

cmtbestgammatest          # confusion matrix in terms of number of classification

p_cmtbestgammatest=(rbind(cmtbestgammatest[1,]/(sum(cmtbestgammatest[1,])),cmtbestgammatest[2,]/(sum(cmtbestgammatest[2,]))))
                          
p_cmtbestgammatest#confusion matrix in terms of percentage 

error11bestgammatest=sqrt((p_cmtbestgammatest[1,])*(1-p_cmtbestgammatest[1,])/sum(p_cmtbestgammatest[1,]))
                          
error12bestgammatest=sqrt((p_cmtbestgammatest[2,])*(1-p_cmtbestgammatest[2,])/sum(p_cmtbestgammatest[2,]))
                          
error3bestgammatest=rbind(error11bestgammatest, error12bestgammatest) 

error3bestgammatest #error on the confusion matrix percentage for best model



#
#                               Error of estimation for best model (Training Set)
#

options(digits=4)

matrix(errorbestgamma1)            #error of estimation for best model

bestmodel1gamma              #Percentage of correct classification for the best model with 95%  Confidence Interval computed by r

resultsbestgamma1         #Percentage of correct classification for the best model with 95%  Confidence Interval manual computation

error3bestgamma         #Error on the confusion matrix for the best model



#
#                                Error of estimation for best model (Test Set)
#

options(digits=4)

matrix(errorbestgammatest)             #Error of estimation for best model

bestmodel1gammatest  #Percentage of correct classification for the best model with 95%  Confidence Interval computed by r

resultsbestgammatest #Percentage of correct classification for the best model with 95%  Confidence Interval manual computation

error3bestgammatest  #Error on the confusion matrix for the best model





#
#             PART 6A:
#
#                     SVM classification using a polynomial kernel
#

#
#               Launch the svm on the train data set for polynomial kernel

svmfitpolynomial =svm(y~.,x,type="C-classification",kernel="polynomial",degree=4,coef0=1,cost=1,gamma=1,scale=FALSE)
                      

#
#                           Number and ratio of support vectors
#


options(digits=4)

nsvpolynomial = svmfitpolynomial$nSV

nsvpolynomial          #number of support vectors


Spolynomial=svmfitpolynomial$tot.nSV

Spolynomial             #total number of support vectors

spolynomial=svmfitpolynomial$tot.nSV/nrow(x) 

spolynomial            #ratio of number of support vectors over cases





#
#                         Prediction on both training and test data set
#


y_predpolynomial = predict(svmfitpolynomial, x)     #prediction on the training set

y_test_predpolynomial = predict(svmfitpolynomial, x_test) #prediction on the test set




#
#                      Percentage of correct classification for training set using the polynomial kernel
#



options(digits=4)

cftpolynomial=confusionMatrix(y_predpolynomial, as.factor(y))

Predpolynomialtrain=cftpolynomial$overall[1]

Predpolynomialtrain1= data.frame(t(matrix(c(cftpolynomial$overall[1:4]))))

Predpolynomialtrain1$X2=NULL; colnames(Predpolynomialtrain1) =  c("Accuracy","AccuracyLower","AccuracyUpper")

Predpolynomialtrain1 #Percentage of correct classification on the training set with 95%  Confidence Interval computed by r



errorpolynomial= sqrt(Predpolynomialtrain*(1-Predpolynomialtrain)/nrow(data.frame(y_predpolynomial)))
                      
AccuracyLowerpolynomial=(-1.6*errorpolynomial)+Predpolynomialtrain

AccuracyUpperpolynomial= (1.6*errorpolynomial)+Predpolynomialtrain

resultspolynomial= data.frame(t(matrix(c(Predpolynomialtrain,AccuracyLowerpolynomial,AccuracyUpperpolynomial))))
                                         
colnames(resultspolynomial) = c("Accuracy","CI(AccuracyLower)","CI(AccuracyUpper)")
                                
resultspolynomial #Percentage of correct classification on the training set with 95%  Confidence Interval manual computation




#
#                  Percentage of correct classification for test set using a polynomial kernel
#


options(digits=4)

cftestpolynomial=confusionMatrix(y_test_predpolynomial,as.factor(y_test))

PredTestpolynomial = cftestpolynomial$overall[1]

PredTestpolynomial1= data.frame(t(matrix(c(cftestpolynomial$overall[1:4]))))

PredTestpolynomial1$X2=NULL; colnames(PredTestpolynomial1) =c("Accuracy","AccuracyLower","AccuracyUpper")
  
PredTestpolynomial1 #Percentage of correct classification on the test set with  Confidence Interval computed by r



error1polynomial= sqrt(PredTestpolynomial *(1-PredTestpolynomial)/nrow(data.frame(y_test_predpolynomial)))
                       
AccuracyLowertpolynomial=(-1.6*error1polynomial)+PredTestpolynomial 

AccuracyUppertpolynomial= (1.6*error1polynomial)+PredTestpolynomial

resultstpolynomial1= data.frame(t(matrix(c(PredTestpolynomial, AccuracyLowertpolynomial,AccuracyUppertpolynomial))))
                                          
colnames(resultstpolynomial1) = c("Accuracy","CI(AccuracyLower)", "CI(AccuracyUpper)")
                                 
resultstpolynomial1#Percentage of correct classification on the test set with  Confidence Interval manual computation




#
#                       Confusion Matrix for training set using the polynomial kernel
#


options(digits=4)

cmttpolynomial1=cftpolynomial$table

cmttpolynomial1             # Confusion matrix in terms of numbers of correct classification



p_cmttpolynomial1=(rbind(cmttpolynomial1[1,]/(sum(cmttpolynomial1[1,])),
                         
                         cmttpolynomial1[2,]/(sum(cmttpolynomial1[2,]))))

p_cmttpolynomial1            #confusion matrix in terms of percentage  for test set

error11tpolynomial1= sqrt((p_cmttpolynomial1[1,])*(1-p_cmttpolynomial1[1,])/
                            
                            sum(p_cmttpolynomial1[1,]))

error12tpolynomial1= sqrt((p_cmttpolynomial1[2,])*(1-p_cmttpolynomial1[2,])/
                            
                            sum(p_cmttpolynomial1[2,]))

error3tpolynomial1 = rbind(error11tpolynomial1,error12tpolynomial1) 

error3tpolynomial1  #error on the confusion matrix percentage for train set





#
#                          Confusion Matrix for test set using the polynomial kernel
#




options(digits=4)

ctepolynomial1 = cftestpolynomial$table

ctepolynomial1   #confusion matrix in terms of numbers  

p_ctepolynomial1=(rbind(ctepolynomial1[1,]/(sum(ctepolynomial1[1,])),
                        
                        ctepolynomial1[2,]/(sum(ctepolynomial1[2,]))))



p_ctepolynomial1          #confusion matrix in terms of percentage 


error11tepolynomial1= sqrt((p_ctepolynomial1[1,])*(1-p_ctepolynomial1[1,])
                           
                           /sum(p_ctepolynomial1[1,]))

error12tepolynomial1= sqrt((p_ctepolynomial1[2,])*(1-p_ctepolynomial1[2,])
                           
                           /sum(p_ctepolynomial1[2,]))

error3tepolynomial11 = rbind(error11tepolynomial1,error12tepolynomial1) 

error3tepolynomial11             #error on the confusion matrix percentage for test set





#
#                      Errors of estimation for polynomial kernel (Training Set)
#
 
options(digits=4)

matrix(errorpolynomial) #error of estimation for PredTrain

Predpolynomialtrain1    #Percentage of correct classification on the training set with  Confidence Interval computed by r

resultspolynomial       #Percentage of correct classification on the training set with  Confidence Interval manual computation

error3tpolynomial1      #error on the confusion matrix for the train setresultspolynomial


#
#
#    PART 6B:
#
#           Optimization of the parameter "cost"and "a">0 for polynomial kernel
#

 
#
#              Launch the svm for 5 values of the coefficient(a) and 5 values of the cost
#


options(digits=4)

tune_poly_optimize = tune.svm(as.factor(X5)~.,data=total_train,type="C-classification",
                              
                              kernel = "polynomial", degree = 4, coef0 = c(0.05, 0.5, 1, 2,3 ),
                              
                              cost = c(0.01, 0.1 , 1,5, 10), gamma=1, scale =FALSE)

tune_poly_optimize$performances       # performance results for the 5 different costs and 5 different coefficients 

tune_poly_optimize$best.parameters        # best model





#               Plot of Error and Dispersion for Analysis


plot(tune_poly_optimize$performances$cost,tune_poly_optimize$performances$error,xlim=range(c(tune_poly_optimize$performances$cost)),
     
     ylim=range(c(tune_poly_optimize$performances$error, tune_poly_optimize$performances$dispersion)),
                  
     col="red", pch=16, cex=0.5, xlab = "Cost", ylab=" Error and Dispersion", 
     
     main='2 Dimensional Scatter Plots', col.axis='red')

lines(lowess(tune_poly_optimize$performances$cost,tune_poly_optimize$performances$error),col="red", pch=16)
             
points(tune_poly_optimize$performances$cost,tune_poly_optimize$performances$dispersion,col="blue", pch=16, cex=0.5)
       
lines(lowess(tune_poly_optimize$performances$cost,tune_poly_optimize$performances$dispersion),col="blue", pch=16)
             
legend(x=5,y=0.1,legend=c('Error','Dispersion'),col=c('red','blue'),pch=c(16, 16))



#
#               Plot of Error and Dispersion for Analysis
#


plot(tune_poly_optimize$performances$cost,tune_poly_optimize$performances$error,
     
     xlim=range(c(tune_poly_optimize$performances$cost)),ylim=range(c(tune_poly_optimize$performances$error,
     
      tune_poly_optimize$performances$dispersion)),
     
     col="red", pch=16, cex=0.5, xlab = "Cost", ylab=" Error and Dispersion", 
     
     main='2 Dimensional Scatter Plots', col.axis='red')

lines(lowess(tune_poly_optimize$performances$cost,
             
             tune_poly_optimize$performances$error),col="red", pch=16)

points(tune_poly_optimize$performances$cost,
       
       tune_poly_optimize$performances$dispersion,col="blue", pch=16, cex=0.5)

lines(lowess(tune_poly_optimize$performances$cost,tune_poly_optimize$performances$dispersion),col="blue", pch=16)
             
             
legend(x=7,y=0.51,legend=c('Error','Dispersion'),col=c('red','blue'),pch=c(16, 16))



#
#                Prediction on both training and test data for the best model using cost=5  and coef0 = 0.05
#


bestmodelpolynomial=tune_poly_optimize$best.model

ybestpolypred = predict(bestmodelpolynomial,x) #Train set

ybestpolypredtest = predict(bestmodelpolynomial,x_test) #Test set


#
#                  Percentage of correct classification for the best polynomial model (Training set)
#


options(digits=4)

cftbestpoly=confusionMatrix(ybestpolypred, as.factor(y))

bestmodel12poly=cftbestpoly$overall[1]

bestmodel1poly= data.frame(t(matrix(c(cftbestpoly$overall[1:4]))))

bestmodel1poly$X2=NULL; colnames(bestmodel1poly) = c("Accuracy","AccuracyLower","AccuracyUpper")
                                                     
bestmodel1poly #Percentage of correct classification on the best mdoel with  Confidence Interval computed by r




errorbestpoly1= sqrt(bestmodel12poly*(1-bestmodel12poly)/nrow(data.frame(ybestpolypred)))
                       
AccuracyLowerbestpoly1=(-1.6*errorbestpoly1)+bestmodel12poly

AccuracyUpperbestpoly1= (1.6*errorbestpoly1)+bestmodel12poly

resultsbestpoly1= data.frame(t(matrix(c(bestmodel12poly, AccuracyLowerbestpoly1, AccuracyUpperbestpoly1))))
                                        
colnames(resultsbestpoly1)=c("Accuracy","CI(AccuracyLower)","CI(AccuracyUpper)")

resultsbestpoly1     #Percentage of correct classification on the best model with  Confidence Interval manual computation

  

#
#                     Percentage of correct classification for the best polynomial model (Test set)
#



options(digits=4)

cftbestpolytest=confusionMatrix(ybestpolypredtest, as.factor(y_test))

bestmodel12polytest=cftbestpolytest$overall[1]

bestmodel1polytest= data.frame(t(matrix(c(cftbestpolytest$overall[1:4]))))

bestmodel1polytest$X2=NULL; colnames(bestmodel1polytest) = c("Accuracy","AccuracyLower","AccuracyUpper")
                                                             
bestmodel1polytest #Percentage of correct classification on the best mdoel with  Confidence Interval computed by r




errorbestpolytest= sqrt(bestmodel12polytest*(1-bestmodel12polytest)/nrow(data.frame(ybestpolypredtest)))
                        
AccuracyLowerbestpolytest=(-1.6*errorbestpolytest)+bestmodel12polytest

AccuracyUpperbestpolytest= (1.6*errorbestpolytest)+bestmodel12polytest

resultsbestpolytest= data.frame(t(matrix(c(bestmodel12polytest,AccuracyLowerbestpolytest,AccuracyUpperbestpolytest))))
                                           
colnames(resultsbestpolytest) = c("Accuracy","CI(AccuracyLower)", "CI(AccuracyUpper)")
                                 
resultsbestpolytest #Percentage of correct classification on the best model with Confidence Interval manual computation




#
#                          Confusion Matrix for best model for the training set
#



options(digits=4)

cmtbestpoly=cftbestpoly$table

cmtbestpoly                  # confusion matrix in terms of numbers

p_cmtbestpoly=(rbind(cmtbestpoly[1,]/(sum(cmtbestpoly[1,])),cmtbestpoly[2,]/(sum(cmtbestpoly[2,]))))

                     
p_cmtbestpoly                #confusion matrix in terms of percentage 



error11bestpoly= sqrt((p_cmtbestpoly[1,])*(1-p_cmtbestpoly[1,]) /sum(p_cmtbestpoly[1,]))
                     
error12bestpoly= sqrt((p_cmtbestpoly[2,])*(1-p_cmtbestpoly[2,])/sum(p_cmtbestpoly[2,]))
                      
error3bestpoly = rbind(error11bestpoly, error12bestpoly) 

error3bestpoly  #error on the confusion matrix percentage for best model




#
#                           Confusion Matrix for best model for the test set
#


options(digits=4)

cmtbestpolytest=cftbestpolytest$table

cmtbestpolytest             # confusion matrix in terms of numbers

p_cmtbestpolytest=(rbind(cmtbestpolytest[1,]/(sum(cmtbestpolytest[1,])), cmtbestpolytest[2,]/(sum(cmtbestpolytest[2,]))))
                         
p_cmtbestpolytest             # confusion matrix in terms of percentage 



error11bestpolytest= sqrt((p_cmtbestpolytest[1,])*(1-p_cmtbestpolytest[1,])/sum(p_cmtbestpolytest[1,]))
                          
error12bestpolytest= sqrt((p_cmtbestpolytest[2,])*(1-p_cmtbestpolytest[2,]) /sum(p_cmtbestpolytest[2,]))
                         
error3bestpolytest = rbind(error11bestpolytest, error12bestpolytest)

error3bestpolytest  #error on the confusion matrix percentage for best model




#
#                               Error of estimation for best model (Training set)
#


options(digits=4)

matrix(errorbestpoly1) #error of estimation for best model

bestmodel1poly  #Percentage of correct classification for the best model with  Confidence Interval computed by r

resultsbestpoly1 #Percentage of correct classification for the best model with Confidence Interval manual computation

error3bestpoly  #error on the confusion matrix for the best model



#
#                                 Error of estimation for best model (Test set)
#

options(digits=4)

matrix(errorbestpolytest) #error of estimation for best model

bestmodel1polytest  #Percentage of correct classification for the best model with Confidence Interval computed by r

resultsbestpolytest #Percentage of correct classification for the best model with Confidence Interval manual computation

error3bestpolytest  #error on the confusion matrix for the best model















































